{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6570df51c20c29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-08T07:52:18.236390Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "\n",
    "# -----------------------\n",
    "# 2 CAMERA STREAM URLS\n",
    "\n",
    "# -----------------------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/101\",   # cam_id = \n",
    "\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.3\n",
    "FRAME_WIDTH = 630\n",
    "\n",
    "\n",
    "FRAME_HEIGHT = 480\n",
    "SKIP_FRAMES = 2   \n",
    "# YOLO every 3rd frame → reduces load\n",
    "\n",
    "# Raspberry Pi HTTP server\n",
    "PI_IP = \"10.1.193.78\"\n",
    "PI_PORT = 5000\n",
    "\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_HTTP_INTERVAL = 0.5  # seconds between HTTP calls per camera\n",
    "\n",
    "# Load model\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# HTTP helper (non-blocking)\n",
    "def send_relay_command(cam_id, state):\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "    def _do_request(u):\n",
    "        try:\n",
    "            r = requests.get(u, timeout=1.0)\n",
    "        except Exception as e:\n",
    "            print(f\"[NET] Failed to send {u}: {e}\")    \n",
    "    t = threading.Thread(target=_do_request, args=(url,), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "last_http_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_detection_time = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    now = time.time()\n",
    "    if new_state:\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    if new_state != last_state[cam_id]:\n",
    "\n",
    "        if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "            state_str = \"on\" if new_state else \"off\"\n",
    "            send_relay_command(cam_id, state_str)\n",
    "            last_http_ts[cam_id] = now\n",
    "            last_state[cam_id] = new_state\n",
    "            print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open RTSP stream\")\n",
    "        return\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            try: frame_queue.get_nowait()\n",
    "            except: pass\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_counter += 1\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model(frame, conf=CONFIDENCE, verbose=False)\n",
    "                human_detected = False\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    for cls in r.boxes.cls.cpu().numpy():\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "                    if human_detected:\n",
    "                        break\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "                publish_state_if_changed(cam_id, human_detected)\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Auto-off if no detection for AUTO_OFF_SECONDS\n",
    "        if last_state[cam_id] and (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "            if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                send_relay_command(cam_id, \"off\")\n",
    "                last_http_ts[cam_id] = time.time()\n",
    "                last_state[cam_id] = False\n",
    "                print(f\"[AUTO-OFF] room{cam_id} -> OFF (no detection for {AUTO_OFF_SECONDS}s)\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start threads\n",
    "frame_queues = []\n",
    "num_cams = len(CAMERA_URLS)\n",
    "for i, url in enumerate(CAMERA_URLS):\n",
    "    cam_id = i + 1\n",
    "    q = queue.Queue(maxsize=1)\n",
    "    frame_queues.append(q)\n",
    "    threading.Thread(target=camera_reader, args=(url, q, cam_id), daemon=True).start()\n",
    "    threading.Thread(target=yolo_worker, args=(q, cam_id), daemon=True).start()\n",
    "\n",
    "print(f\"{num_cams}-Camera Human Detection Running...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d0bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77113936c53510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "\n",
    "# -----------------------\n",
    "# 2 CAMERA STREAM URLS\n",
    "# -----------------------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/101\",   # cam_id = 1\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.104:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.84:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.85:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.80:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.100:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.89:554/Streaming/Channels/101\",\n",
    "\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.55\n",
    "FRAME_WIDTH = 630\n",
    "FRAME_HEIGHT = 480\n",
    "SKIP_FRAMES = 4   # YOLO every 3rd frame → reduces load\n",
    "\n",
    "# Raspberry Pi HTTP server\n",
    "PI_IP = \"10.1.193.78\"\n",
    "PI_PORT = 5000\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_HTTP_INTERVAL = 0.5  # seconds between HTTP calls per camera\n",
    "\n",
    "# Load model\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# HTTP helper (non-blocking)\n",
    "def send_relay_command(cam_id, state):\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "    def _do_request(u):\n",
    "        try:\n",
    "            r = requests.get(u, timeout=1.0)\n",
    "        except Exception as e:\n",
    "            print(f\"[NET] Failed to send {u}: {e}\")\n",
    "    t = threading.Thread(target=_do_request, args=(url,), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "last_http_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_detection_time = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    now = time.time()\n",
    "    if new_state:\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    if new_state != last_state[cam_id]:\n",
    "        if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "            state_str = \"on\" if new_state else \"off\"\n",
    "            send_relay_command(cam_id, state_str)\n",
    "            last_http_ts[cam_id] = now\n",
    "            last_state[cam_id] = new_state\n",
    "            print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open RTSP stream\")\n",
    "        return\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            try: frame_queue.get_nowait()\n",
    "            except: pass\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_counter += 1\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model(frame, conf=CONFIDENCE, verbose=False)\n",
    "                human_detected = False\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    for cls in r.boxes.cls.cpu().numpy():\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "                    if human_detected:\n",
    "                        break\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "                publish_state_if_changed(cam_id, human_detected)\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Auto-off if no detection for AUTO_OFF_SECONDS\n",
    "        if last_state[cam_id] and (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "            if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                send_relay_command(cam_id, \"off\")\n",
    "                last_http_ts[cam_id] = time.time()\n",
    "                last_state[cam_id] = False\n",
    "                print(f\"[AUTO-OFF] room{cam_id} -> OFF (no detection for {AUTO_OFF_SECONDS}s)\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start threads\n",
    "frame_queues = []\n",
    "num_cams = len(CAMERA_URLS)\n",
    "for i, url in enumerate(CAMERA_URLS):\n",
    "    cam_id = i + 1\n",
    "    q = queue.Queue(maxsize=1)\n",
    "    frame_queues.append(q)\n",
    "    threading.Thread(target=camera_reader, args=(url, q, cam_id), daemon=True).start()\n",
    "    threading.Thread(target=yolo_worker, args=(q, cam_id), daemon=True).start()\n",
    "\n",
    "print(f\"{num_cams}-Camera Human Detection Running...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ---------- GPU HARDWARE DECODING ----------\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \\\n",
    "    \"video_codec;h264_cuvid|rtsp_transport;tcp|max_delay;0\"\n",
    "\n",
    "# ---------- CAMERA URLs USING SUBSTREAM (102) ----------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.104:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.84:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.85:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.95:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.96:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.89:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.:554/Streaming/Channels/102\"\n",
    "\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "# ---------- DEVICE ----------\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 0\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# CAMERA THREAD\n",
    "# ----------------------------------------------------\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open stream\")\n",
    "        return\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "        # Drop oldest frame (prevent lag)\n",
    "        if frame_queue.full():\n",
    "            try:\n",
    "                frame_queue.get_nowait()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# YOLO THREAD\n",
    "# ----------------------------------------------------\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "\n",
    "            # Always fetch latest frame → zero lag\n",
    "            while not frame_queue.empty():\n",
    "                frame = frame_queue.get()\n",
    "\n",
    "            frame_counter += 1\n",
    "            human_detected = False\n",
    "\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model.predict(\n",
    "                    frame,\n",
    "                    conf=CONFIDENCE,\n",
    "                    imgsz=IMG_SIZE,\n",
    "                    device=DEVICE,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    classes = r.boxes.cls.cpu().numpy()\n",
    "                    for cls in classes:\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        else:\n",
    "            time.sleep(0.005)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# MAIN STARTER\n",
    "# ----------------------------------------------------\n",
    "def main():\n",
    "    frame_queues = []\n",
    "    num_cams = len(CAMERA_URLS)\n",
    "\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        frame_queues.append(q)\n",
    "\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    print(f\"{num_cams} Camera Detection Running...\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down...\")\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47013d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import requests  # ADDED for Raspberry Pi HTTP communication\n",
    "\n",
    "# ---------- GPU HARDWARE DECODING ----------\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \\\n",
    "    \"video_codec;h264_cuvid|rtsp_transport;tcp|max_delay;0\"\n",
    "\n",
    "# ---------- CAMERA URLs USING SUBSTREAM (102) ----------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.104:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.84:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.85:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.95:554/Streaming/Channels/102\", \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.96:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.89:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.93:554/Streaming/Channels/102\", \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.98:554/Streaming/Channels/102\", \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.120:554/Streaming/Channels/102\",  \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\", \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.86:554/Streaming/Channels/102\", \n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "# -----------------------------\n",
    "# Raspberry Pi HTTP / Auto-off\n",
    "# -----------------------------\n",
    "PI_IP = \"10.1.193.78\"     # change to your Pi IP\n",
    "PI_PORT = 5000\n",
    "AUTO_OFF_SECONDS = 6      # auto-off after this many seconds without detection\n",
    "MIN_HTTP_INTERVAL = 0.5   # seconds between HTTP calls per camera\n",
    "\n",
    "def send_relay_command(cam_id, state):\n",
    "    \"\"\"\n",
    "    Non-blocking HTTP GET to Raspberry Pi endpoint:\n",
    "      http://<PI_IP>:<PI_PORT>/room{cam_id}/{state}\n",
    "    where state is \"on\" or \"off\".\n",
    "    \"\"\"\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "    def _do_request(u):\n",
    "        try:\n",
    "            requests.get(u, timeout=1.0)\n",
    "        except Exception as e:\n",
    "            print(f\"[NET] Failed to send {u}: {e}\")\n",
    "    t = threading.Thread(target=_do_request, args=(url,), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "# Bookkeeping per camera\n",
    "num_cams = len(CAMERA_URLS)\n",
    "last_http_ts = {i+1: 0.0 for i in range(num_cams)}\n",
    "last_state = {i+1: False for i in range(num_cams)}\n",
    "last_detection_time = {i+1: 0.0 for i in range(num_cams)}\n",
    "state_lock = threading.Lock()\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    now = time.time()\n",
    "    # record detection time on positive\n",
    "    if new_state:\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    # If changed, send HTTP rate-limited\n",
    "    with state_lock:\n",
    "        if new_state != last_state[cam_id]:\n",
    "            if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                state_str = \"on\" if new_state else \"off\"\n",
    "                send_relay_command(cam_id, state_str)\n",
    "                last_http_ts[cam_id] = now\n",
    "                last_state[cam_id] = new_state\n",
    "                print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "# ---------- DEVICE ----------\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 0\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# CAMERA THREAD\n",
    "# ----------------------------------------------------\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open stream\")\n",
    "        return\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "        # Drop oldest frame (prevent lag)\n",
    "        if frame_queue.full():\n",
    "            try:\n",
    "                frame_queue.get_nowait()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# YOLO THREAD (minimal changes: publish state & auto-off)\n",
    "# ----------------------------------------------------\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        if not frame_queue.empty(): \n",
    "            # Always fetch latest frame → zero lag\n",
    "            while not frame_queue.empty():\n",
    "                frame = frame_queue.get()\n",
    "\n",
    "            frame_counter += 1\n",
    "            human_detected = False\n",
    "\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model.predict(\n",
    "                    frame,\n",
    "                    conf=CONFIDENCE,\n",
    "                    imgsz=IMG_SIZE,\n",
    "                    device=DEVICE,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    classes = r.boxes.cls.cpu().numpy()\n",
    "                    for cls in classes:\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "\n",
    "                # <-- NEW: publish state change to Raspberry Pi\n",
    "                publish_state_if_changed(cam_id, human_detected)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        else:\n",
    "            time.sleep(0.005)\n",
    "\n",
    "        # <-- NEW: Auto-off if no detection for AUTO_OFF_SECONDS\n",
    "        with state_lock:\n",
    "            if last_state[cam_id]:\n",
    "                if (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "                    if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                        send_relay_command(cam_id, \"off\")\n",
    "                        last_http_ts[cam_id] = time.time()\n",
    "                        last_state[cam_id] = False\n",
    "                        print(f\"[AUTO-OFF] room{cam_id} -> OFF (no detection for {AUTO_OFF_SECONDS}s)\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# MAIN STARTER\n",
    "# ----------------------------------------------------\n",
    "def main():\n",
    "    frame_queues = []\n",
    "    num_cams = len(CAMERA_URLS)\n",
    "\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        frame_queues.append(q)\n",
    "\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    print(f\"{num_cams} Camera Detection Running...\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down...\")\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "# ---------- GPU HARDWARE DECODING ----------\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \\\n",
    "    \"video_codec;h264_cuvid|rtsp_transport;tcp|max_delay;0\"\n",
    "\n",
    "# ---------- CAMERA URLs USING SUBSTREAM (102) ----------\n",
    "CAMERA_URLS = [\n",
    "    \n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.104:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.96:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",\n",
    "   \n",
    "]\n",
    "\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "# Load Raspberry pi4\n",
    "PI_IP = \"10.1.193.87\"\n",
    "PI_PORT = 5000\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_HTTP_INTERVAL = 0.5  # seconds between HTTP calls per camera\n",
    "\n",
    "# ---------- RPI COMM & STATE (ADD THIS) ----------\n",
    "# Per-camera state dictionaries\n",
    "last_http_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_detection_time = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "def send_relay_command(cam_id, state):\n",
    "    \"\"\"\n",
    "    Non-blocking HTTP GET:\n",
    "        http://<PI_IP>:<PI_PORT>/room{cam_id}/{state}\n",
    "    where state is \"on\" or \"off\".\n",
    "    \"\"\"\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "\n",
    "    def _do_request(u):\n",
    "        try:\n",
    "            requests.get(u, timeout=1.0)\n",
    "        except Exception as e:\n",
    "            print(f\"[NET] Failed to send {u}: {e}\")\n",
    "\n",
    "    t = threading.Thread(target=_do_request, args=(url,), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    \"\"\"\n",
    "    Called after each YOLO decision.\n",
    "    Sends ON/OFF to Pi only when the state changes,\n",
    "    and respects MIN_HTTP_INTERVAL to avoid spamming.\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "\n",
    "    if new_state:\n",
    "        # update last detection timestamp\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    if new_state != last_state[cam_id]:\n",
    "        if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "            state_str = \"on\" if new_state else \"off\"\n",
    "            send_relay_command(cam_id, state_str)\n",
    "            last_http_ts[cam_id] = now\n",
    "            last_state[cam_id] = new_state\n",
    "            print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "# ---------- DEVICE ----------\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 0\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# CAMERA THREAD\n",
    "# ----------------------------------------------------\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open stream\")\n",
    "        return\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(f\"{url}?buffer_size=1\", cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "        # Drop oldest frame (prevent lag)\n",
    "        if frame_queue.full():\n",
    "            try:\n",
    "                frame_queue.get_nowait()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# YOLO THREAD\n",
    "# ----------------------------------------------------\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "\n",
    "            # Always fetch latest frame → zero lag\n",
    "            while not frame_queue.empty():\n",
    "                frame = frame_queue.get()\n",
    "\n",
    "            frame_counter += 1\n",
    "            human_detected = False\n",
    "\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model.predict(\n",
    "                    frame,\n",
    "                    conf=CONFIDENCE,\n",
    "                    imgsz=IMG_SIZE,\n",
    "                    device=DEVICE,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    classes = r.boxes.cls.cpu().numpy()\n",
    "                    for cls in classes:\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "                publish_state_if_changed(cam_id, human_detected) # Send state to Raspberry Pi (ON/OFF) for this camera\n",
    "                \n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        else:\n",
    "            time.sleep(0.005)\n",
    "        # Auto-off if no detection for AUTO_OFF_SECONDS\n",
    "        if last_state[cam_id] and (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "            if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                send_relay_command(cam_id, \"off\")\n",
    "                last_http_ts[cam_id] = time.time()\n",
    "                last_state[cam_id] = False\n",
    "                print(f\"[AUTO-OFF] room{cam_id} -> OFF (no detection for {AUTO_OFF_SECONDS}s)\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# MAIN STARTER\n",
    "# ----------------------------------------------------\n",
    "def main():\n",
    "    frame_queues = []\n",
    "    num_cams = len(CAMERA_URLS)\n",
    "\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        frame_queues.append(q)\n",
    "\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    print(f\"{num_cams} Camera Detection Running...\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down...\")\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "\n",
    "# -----------------------\n",
    "# CAMERA STREAM URLS\n",
    "# -----------------------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/101\",\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.3\n",
    "FRAME_WIDTH = 630\n",
    "FRAME_HEIGHT = 480\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "PI_IP = \"10.1.193.87\"\n",
    "PI_PORT = 5000\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "\n",
    "# === FIX 1: Increase interval so network doesn’t overload ===\n",
    "MIN_HTTP_INTERVAL = 3     # increased from 0.5 to 3 seconds\n",
    "\n",
    "# Load YOLO\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# === FIX 2: Remove threading for HTTP (causing Ethernet driver freeze) ===\n",
    "def send_relay_command(cam_id, state):\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "    try:\n",
    "        requests.get(url, timeout=1.0)\n",
    "    except Exception as e:\n",
    "        print(f\"[NET] Failed: {e}\")\n",
    "\n",
    "last_http_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_detection_time = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    now = time.time()\n",
    "    if new_state:\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    if new_state != last_state[cam_id]:\n",
    "        if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "            state_str = \"on\" if new_state else \"off\"\n",
    "            send_relay_command(cam_id, state_str)\n",
    "            last_http_ts[cam_id] = now\n",
    "            last_state[cam_id] = new_state\n",
    "            print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open RTSP\")\n",
    "        return\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "\n",
    "            # === FIX 3: Add reconnect cooldown to avoid network spam ===\n",
    "            time.sleep(3)\n",
    "\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            try: frame_queue.get_nowait()\n",
    "            except: pass\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_counter += 1\n",
    "\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model(frame, conf=CONFIDENCE, verbose=False)\n",
    "                human_detected = False\n",
    "\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    for cls in r.boxes.cls.cpu().numpy():\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "                    if human_detected:\n",
    "                        break\n",
    "\n",
    "                print(f\"[CAM {cam_id}] {'HUMAN' if human_detected else 'NO HUMAN'}\")\n",
    "                publish_state_if_changed(cam_id, human_detected)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Auto OFF\n",
    "        if last_state[cam_id] and (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "            if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                send_relay_command(cam_id, \"off\")\n",
    "                last_http_ts[cam_id] = time.time()\n",
    "                last_state[cam_id] = False\n",
    "                print(f\"[AUTO-OFF] room{cam_id} -> OFF\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start threads\n",
    "frame_queues = []\n",
    "num_cams = len(CAMERA_URLS)\n",
    "for i, url in enumerate(CAMERA_URLS):\n",
    "    cam_id = i + 1\n",
    "    q = queue.Queue(maxsize=1)\n",
    "    frame_queues.append(q)\n",
    "\n",
    "    threading.Thread(target=camera_reader, args=(url, q, cam_id), daemon=True).start()\n",
    "    threading.Thread(target=yolo_worker, args=(q, cam_id), daemon=True).start()\n",
    "\n",
    "print(f\"{num_cams}-Camera Human Detection Running...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with esp32 working good\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# ================== MQTT CONFIG ==================\n",
    "MQTT_BROKER = \"10.1.193.80\"   # PC IP (broker runs here)\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC_BASE = \"classroom/room\"\n",
    "\n",
    "# ================== CAMERA CONFIG =================\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.94:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_STATE_INTERVAL = 0.5\n",
    "\n",
    "# ================== STATE ==================\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_change_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_detect_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "# ================== MQTT ==================\n",
    "mqtt_client = mqtt.Client(client_id=\"YOLO_PC\")\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"[MQTT] Connected with rc =\", rc)\n",
    "\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "def publish_state(cam_id, state):\n",
    "    now = time.time()\n",
    "    if now - last_change_ts[cam_id] < MIN_STATE_INTERVAL:\n",
    "        return\n",
    "\n",
    "    topic = f\"{MQTT_TOPIC_BASE}{cam_id}\"\n",
    "    payload = \"1\" if state else \"0\"\n",
    "\n",
    "    mqtt_client.publish(topic, payload, qos=0, retain=True)\n",
    "    last_change_ts[cam_id] = now\n",
    "    last_state[cam_id] = state\n",
    "\n",
    "    print(f\"[MQTT] {topic} -> {payload}\")\n",
    "\n",
    "# ================== YOLO ==================\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ================== CAMERA THREAD ==================\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream started\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "# ================== YOLO THREAD ==================\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            time.sleep(0.005)\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        human_detected = False\n",
    "\n",
    "        results = model.predict(\n",
    "            frame,\n",
    "            conf=CONFIDENCE,\n",
    "            imgsz=IMG_SIZE,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is None:\n",
    "                continue\n",
    "            for cls in r.boxes.cls:\n",
    "                if int(cls) == 0:\n",
    "                    human_detected = True\n",
    "                    break\n",
    "\n",
    "        if human_detected:\n",
    "            last_detect_ts[cam_id] = time.time()\n",
    "            print(f\"[CAM {cam_id}] HUMAN\")\n",
    "        else:\n",
    "            print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "\n",
    "        if human_detected != last_state[cam_id]:\n",
    "            publish_state(cam_id, human_detected)\n",
    "\n",
    "        # AUTO OFF\n",
    "        if last_state[cam_id]:\n",
    "            if time.time() - last_detect_ts[cam_id] > AUTO_OFF_SECONDS:\n",
    "                publish_state(cam_id, False)\n",
    "                print(f\"[AUTO-OFF] room{cam_id}\")\n",
    "\n",
    "# ================== MAIN ==================\n",
    "def main():\n",
    "    print(\"Starting YOLO → MQTT system\")\n",
    "\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53459373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40255e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a7621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca3989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multi camera esp32 connection\n",
    "\n",
    "# import cv2\n",
    "# import time\n",
    "# import threading\n",
    "# import queue\n",
    "# import torch\n",
    "# from ultralytics import YOLO\n",
    "# import paho.mqtt.client as mqtt\n",
    "# import sys\n",
    "\n",
    "# # ================== MQTT CONFIG ==================\n",
    "# MQTT_BROKER = \"10.1.193.80\"\n",
    "# MQTT_PORT = 1883\n",
    "# MQTT_TOPIC_BASE = \"classroom/room\"\n",
    "\n",
    "# # ================== CAMERA CONFIG =================\n",
    "# CAMERA_URLS = [\n",
    "#     \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "#     \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",\n",
    "# ]\n",
    "\n",
    "# CONFIDENCE = 0.25\n",
    "# IMG_SIZE = 320\n",
    "# FRAME_WIDTH = 480\n",
    "# FRAME_HEIGHT = 270\n",
    "# SKIP_FRAMES = 2\n",
    "\n",
    "# AUTO_OFF_SECONDS = 6\n",
    "# MIN_STATE_INTERVAL = 0.5\n",
    "\n",
    "# # ================== STATE ==================\n",
    "# last_state = {i + 1: False for i in range(len(CAMERA_URLS))}\n",
    "# last_change_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "# last_detect_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "# last_print_state = {i + 1: None for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "# # ================== MQTT ==================\n",
    "# mqtt_client = mqtt.Client(client_id=f\"YOLO_PC_{int(time.time())}\")\n",
    "\n",
    "# def on_connect(client, userdata, flags, rc):\n",
    "#     print(\"[MQTT] Connected rc =\", rc, flush=True)\n",
    "\n",
    "# mqtt_client.on_connect = on_connect\n",
    "# mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "# mqtt_client.loop_start()\n",
    "\n",
    "# def publish_state(cam_id, state):\n",
    "#     now = time.time()\n",
    "#     if now - last_change_ts[cam_id] < MIN_STATE_INTERVAL:\n",
    "#         return\n",
    "\n",
    "#     topic = f\"{MQTT_TOPIC_BASE}{cam_id}\"\n",
    "#     payload = \"1\" if state else \"0\"\n",
    "\n",
    "#     mqtt_client.publish(topic, payload, retain=True)\n",
    "#     last_change_ts[cam_id] = now\n",
    "#     last_state[cam_id] = state\n",
    "\n",
    "#     print(f\"[MQTT] {topic} -> {payload}\", flush=True)\n",
    "\n",
    "# # ================== YOLO ==================\n",
    "# DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"[YOLO] Using device:\", DEVICE, flush=True)\n",
    "\n",
    "# model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# # ================== CAMERA THREAD ==================\n",
    "# def camera_reader(url, frame_queue, cam_id):\n",
    "#     cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "#     cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "#     print(f\"[CAM {cam_id}] Stream started\", flush=True)\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(f\"[CAM {cam_id}] Reconnecting...\", flush=True)\n",
    "#             cap.release()\n",
    "#             time.sleep(1)\n",
    "#             cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "#             continue\n",
    "\n",
    "#         frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "#         if frame_queue.full():\n",
    "#             frame_queue.get_nowait()\n",
    "#         frame_queue.put(frame)\n",
    "\n",
    "# # ================== YOLO THREAD ==================\n",
    "# def yolo_worker(frame_queue, cam_id):\n",
    "#     print(f\"[YOLO] Worker started for CAM {cam_id}\", flush=True)\n",
    "\n",
    "#     frame_count = 0\n",
    "\n",
    "#     while True:\n",
    "#         if frame_queue.empty():\n",
    "#             time.sleep(0.01)\n",
    "#             continue\n",
    "\n",
    "#         frame = frame_queue.get()\n",
    "#         frame_count += 1\n",
    "\n",
    "#         if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "#             continue\n",
    "\n",
    "#         human_detected = False\n",
    "\n",
    "#         results = model.predict(\n",
    "#             frame,\n",
    "#             conf=CONFIDENCE,\n",
    "#             imgsz=IMG_SIZE,\n",
    "#             device=DEVICE,\n",
    "#             verbose=False\n",
    "#         )\n",
    "\n",
    "#         for r in results:\n",
    "#             if r.boxes is not None:\n",
    "#                 for cls in r.boxes.cls:\n",
    "#                     if int(cls) == 0:\n",
    "#                         human_detected = True\n",
    "#                         break\n",
    "\n",
    "#         # ===== PRINT ONLY ON CHANGE =====\n",
    "#         if human_detected != last_print_state[cam_id]:\n",
    "#             if human_detected:\n",
    "#                 print(f\"[CAM {cam_id}] HUMAN DETECTED\", flush=True)\n",
    "#             else:\n",
    "#                 print(f\"[CAM {cam_id}] NO HUMAN\", flush=True)\n",
    "#             last_print_state[cam_id] = human_detected\n",
    "\n",
    "#         if human_detected:\n",
    "#             last_detect_ts[cam_id] = time.time()\n",
    "\n",
    "#         if human_detected != last_state[cam_id]:\n",
    "#             publish_state(cam_id, human_detected)\n",
    "\n",
    "#         if last_state[cam_id] and time.time() - last_detect_ts[cam_id] > AUTO_OFF_SECONDS:\n",
    "#             print(f\"[CAM {cam_id}] AUTO OFF\", flush=True)\n",
    "#             publish_state(cam_id, False)\n",
    "\n",
    "# # ================== MAIN ==================\n",
    "# def main():\n",
    "#     print(\"[SYSTEM] Starting YOLO → MQTT system\", flush=True)\n",
    "\n",
    "#     for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "#         q = queue.Queue(maxsize=1)\n",
    "#         threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "#         threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "#     while True:\n",
    "#         time.sleep(1)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi camera esp32 connection\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt\n",
    "import sys\n",
    "\n",
    "# ================== MQTT CONFIG ==================\n",
    "MQTT_BROKER = \"10.1.193.80\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC_BASE = \"classroom/room\"\n",
    "\n",
    "# ================== CAMERA CONFIG =================\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "AUTO_OFF_SECONDS = 1\n",
    "MIN_STATE_INTERVAL = 0.5\n",
    "\n",
    "# ================== STATE ==================\n",
    "last_state = {i + 1: False for i in range(len(CAMERA_URLS))}\n",
    "last_change_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_detect_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_print_state = {i + 1: None for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "# ================== MQTT ==================\n",
    "mqtt_client = mqtt.Client(client_id=f\"YOLO_PC_{int(time.time())}\")\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"[MQTT] Connected rc =\", rc, flush=True)\n",
    "\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "def publish_state(cam_id, state):\n",
    "    now = time.time()\n",
    "    if now - last_change_ts[cam_id] < MIN_STATE_INTERVAL:\n",
    "        return\n",
    "\n",
    "    topic = f\"{MQTT_TOPIC_BASE}{cam_id}\"\n",
    "    payload = \"1\" if state else \"0\"\n",
    "\n",
    "    mqtt_client.publish(topic, payload, retain=True)\n",
    "    last_change_ts[cam_id] = now\n",
    "    last_state[cam_id] = state\n",
    "\n",
    "    print(f\"[MQTT] {topic} -> {payload}\", flush=True)\n",
    "\n",
    "# ================== YOLO ==================\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"[YOLO] Using device:\", DEVICE, flush=True)\n",
    "\n",
    "model = YOLO(\"yolo11x.pt\")\n",
    "\n",
    "# ================== CAMERA THREAD ==================\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream started\", flush=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\", flush=True)\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "# ================== YOLO THREAD ==================\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    print(f\"[YOLO] Worker started for CAM {cam_id}\", flush=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        display_frame = frame.copy()\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "            cv2.imshow(window_name, display_frame)\n",
    "            cv2.waitKey(1)\n",
    "            continue\n",
    "\n",
    "        detected_this_frame = False\n",
    "\n",
    "        results = model.predict(\n",
    "            frame,\n",
    "            conf=CONFIDENCE,\n",
    "            imgsz=IMG_SIZE,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                for box in r.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "\n",
    "                    if cls == 0:\n",
    "                        detected_this_frame = True\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.putText(\n",
    "                            display_frame,\n",
    "                            f\"Person {conf:.2f}\",\n",
    "                            (x1, y1 - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            (0, 255, 0),\n",
    "                            2\n",
    "                        )\n",
    "\n",
    "        # ================== STABLE LOGIC ==================\n",
    "\n",
    "        if detected_this_frame:\n",
    "            last_detect_ts[cam_id] = time.time()\n",
    "\n",
    "            if not last_state[cam_id]:\n",
    "                print(f\"[CAM {cam_id}] HUMAN DETECTED (STABLE ON)\", flush=True)\n",
    "                publish_state(cam_id, True)\n",
    "\n",
    "        # AUTO OFF ONLY AFTER TIMEOUT\n",
    "        if last_state[cam_id]:\n",
    "            if time.time() - last_detect_ts[cam_id] > AUTO_OFF_SECONDS:\n",
    "                print(f\"[CAM {cam_id}] HUMAN LEFT (STABLE OFF)\", flush=True)\n",
    "                publish_state(cam_id, False)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "# ================== MAIN ==================\n",
    "def main():\n",
    "    print(\"[SYSTEM] Starting YOLO → MQTT system\", flush=True)\n",
    "\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # working code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e262f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with segmentation of camera id 3 of the room h514\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# ================== MQTT CONFIG =================\n",
    "MQTT_BROKER = \"10.1.193.80\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC_BASE = \"classroom/room\"\n",
    "\n",
    "# ================== CAMERA CONFIG =================\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.93:554/Streaming/Channels/101\"  # CAM 3\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_STATE_INTERVAL = 0.5\n",
    "\n",
    "# ================== STATE =================\n",
    "last_state = {i + 1: False for i in range(len(CAMERA_URLS))}\n",
    "last_change_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_detect_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "# ================== MQTT =================\n",
    "mqtt_client = mqtt.Client(client_id=f\"YOLO_PC_{int(time.time())}\")\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"[MQTT] Connected rc =\", rc, flush=True)\n",
    "\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "def publish_state(cam_id, payload):\n",
    "    now = time.time()\n",
    "    if last_state[cam_id] == payload:\n",
    "        return\n",
    "    if now - last_change_ts[cam_id] < MIN_STATE_INTERVAL:\n",
    "        return\n",
    "\n",
    "    topic = f\"{MQTT_TOPIC_BASE}{cam_id}\"\n",
    "    mqtt_client.publish(topic, payload, retain=True)\n",
    "    last_change_ts[cam_id] = now\n",
    "    last_state[cam_id] = payload\n",
    "\n",
    "    # Print ON/OFF state\n",
    "    if payload == \"0\":\n",
    "        print(f\"[STATE] Camera {cam_id} OFF\", flush=True)\n",
    "    else:\n",
    "        print(f\"[STATE] Camera {cam_id} ON\", flush=True)\n",
    "\n",
    "# ================== YOLO =================\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ================== POLYGON SEGMENTS (CAM 3) =================\n",
    "# Saved polygons from your clicks (segments 1-6)\n",
    "POLYGONS = [\n",
    "    [(29, 107), (142, 72), (232, 103), (59, 164)],\n",
    "    [(67, 169), (104, 221), (318, 132), (243, 103)],\n",
    "    [(330, 136), (478, 184), (463, 267), (57, 251)],\n",
    "    [(145, 69), (253, 40), (338, 60), (241, 99)],\n",
    "    [(346, 67), (423, 85), (327, 128), (254, 102)],\n",
    "    [(335, 131), (437, 89), (478, 106), (479, 174)]\n",
    "]\n",
    "\n",
    "def point_in_polygon(pt, poly):\n",
    "    # Ray-casting algorithm to check if point is inside polygon\n",
    "    x, y = pt\n",
    "    inside = False\n",
    "    n = len(poly)\n",
    "    px, py = poly[0]\n",
    "    for i in range(1, n + 1):\n",
    "        sx, sy = poly[i % n]\n",
    "        if ((sy > y) != (py > y)) and (x < (px - sx) * (y - sy) / (py - sy + 1e-6) + sx):\n",
    "            inside = not inside\n",
    "        px, py = sx, sy\n",
    "    return inside\n",
    "\n",
    "def get_segment_id(cx, cy):\n",
    "    for idx, poly in enumerate(POLYGONS, start=1):\n",
    "        if point_in_polygon((cx, cy), poly):\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "# ================== CAMERA THREAD =================\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream started\", flush=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "# ================== YOLO THREAD =================\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        human_detected = False\n",
    "        detected_segment = None\n",
    "\n",
    "        results = model.predict(\n",
    "            frame,\n",
    "            conf=CONFIDENCE,\n",
    "            imgsz=IMG_SIZE,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                for box in r.boxes:\n",
    "                    if int(box.cls[0]) == 0:\n",
    "                        human_detected = True\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        cx = (x1 + x2) // 2\n",
    "                        cy = (y1 + y2) // 2\n",
    "                        # Draw bounding box around detected human\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(display_frame, \"Human\", (x1, y1 - 5),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                        if cam_id == 3:\n",
    "                            detected_segment = get_segment_id(cx, cy)\n",
    "                            # Print segment where human is detected\n",
    "                            if detected_segment is not None:\n",
    "                                print(f\"[DETECTED] Human in segment {detected_segment}\", flush=True)\n",
    "                        break\n",
    "\n",
    "        # -------- DISPLAY CAM 3 --------\n",
    "        if cam_id == 3:\n",
    "            # Draw all polygons\n",
    "            for idx, poly in enumerate(POLYGONS, start=1):\n",
    "                for i in range(len(poly)):\n",
    "                    cv2.line(display_frame, poly[i], poly[(i + 1) % len(poly)], (0, 255, 255), 2)\n",
    "                cv2.putText(display_frame, f\"SEG {idx}\", poly[0], cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "            if detected_segment is not None:\n",
    "                cv2.putText(\n",
    "                    display_frame,\n",
    "                    f\"DETECTED SEG {detected_segment}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "            cv2.imshow(\"CAM 3 - Segmented\", display_frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        # -------- STATE HANDLING --------\n",
    "        if human_detected:\n",
    "            last_detect_ts[cam_id] = time.time()\n",
    "            if cam_id == 3 and detected_segment is not None:\n",
    "                publish_state(cam_id, str(detected_segment))\n",
    "            else:\n",
    "                publish_state(cam_id, \"1\")\n",
    "\n",
    "        if last_state[cam_id] and time.time() - last_detect_ts[cam_id] > AUTO_OFF_SECONDS:\n",
    "            publish_state(cam_id, \"0\")\n",
    "\n",
    "# ================== MAIN =================\n",
    "def main():\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746c19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d39c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATE] Camera 3 ON\n",
      "[CAM 3] SEG 1 ON\n",
      "[STATE] Camera 3 ON\n",
      "[CAM 3] SEG 1 OFF\n",
      "[CAM 3] SEG 4 ON\n",
      "[CAM 3] SEG 4 OFF\n",
      "[CAM 3] SEG 4 ON\n",
      "[STATE] Camera 3 ON\n",
      "[CAM 3] SEG 2 ON\n",
      "[STATE] Camera 3 ON\n",
      "[CAM 3] SEG 3 ON\n",
      "[STATE] Camera 3 ON\n"
     ]
    }
   ],
   "source": [
    "#with 2 and 3\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# ================== MQTT CONFIG =================\n",
    "MQTT_BROKER = \"10.1.193.80\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC_BASE = \"classroom/room\"\n",
    "\n",
    "# ================== CAMERA CONFIG =================\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",  # CAM 2\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.93:554/Streaming/Channels/101\"   # CAM 3\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_STATE_INTERVAL = 0.5\n",
    "\n",
    "# ================== STATE =================\n",
    "last_state = {i + 1: False for i in range(len(CAMERA_URLS))}\n",
    "last_change_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_detect_ts = {i + 1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "# ================== MQTT =================\n",
    "mqtt_client = mqtt.Client(client_id=f\"YOLO_PC_{int(time.time())}\")\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"[MQTT] Connected rc =\", rc, flush=True)\n",
    "\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "def publish_state(cam_id, payload):\n",
    "    now = time.time()\n",
    "    if last_state[cam_id] == payload:\n",
    "        return\n",
    "    if now - last_change_ts[cam_id] < MIN_STATE_INTERVAL:\n",
    "        return\n",
    "\n",
    "    topic = f\"{MQTT_TOPIC_BASE}{cam_id}\"\n",
    "    mqtt_client.publish(topic, payload, retain=True)\n",
    "    last_change_ts[cam_id] = now\n",
    "    last_state[cam_id] = payload\n",
    "\n",
    "    if payload == \"0\":\n",
    "        print(f\"[STATE] Camera {cam_id} OFF\", flush=True)\n",
    "    else:\n",
    "        print(f\"[STATE] Camera {cam_id} ON\", flush=True)\n",
    "\n",
    "# ================== YOLO =================\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ================== IGNORE POLYGON (CAM 2) =================\n",
    "IGNORE_POLYGON_CAM2 = [\n",
    "    (405, 125),\n",
    "    (439, 144),\n",
    "    (459, 45),\n",
    "    (416, 24)\n",
    "]\n",
    "\n",
    "# ================== POLYGON SEGMENTS (CAM 3) =================\n",
    "POLYGONS = [\n",
    "    [(29, 107), (142, 72), (232, 103), (59, 164)],\n",
    "    [(67, 169), (104, 221), (318, 132), (243, 103)],\n",
    "    [(330, 136), (478, 184), (463, 267), (57, 251)],\n",
    "    [(145, 69), (253, 40), (338, 60), (241, 99)],\n",
    "    [(346, 67), (423, 85), (327, 128), (254, 102)],\n",
    "    [(335, 131), (437, 89), (478, 106), (479, 174)]\n",
    "]\n",
    "\n",
    "def point_in_polygon(pt, poly):\n",
    "    x, y = pt\n",
    "    inside = False\n",
    "    n = len(poly)\n",
    "    px, py = poly[0]\n",
    "    for i in range(1, n + 1):\n",
    "        sx, sy = poly[i % n]\n",
    "        if ((sy > y) != (py > y)) and (x < (px - sx) * (y - sy) / (py - sy + 1e-6) + sx):\n",
    "            inside = not inside\n",
    "        px, py = sx, sy\n",
    "    return inside\n",
    "\n",
    "def get_segment_id(cx, cy):\n",
    "    for idx, poly in enumerate(POLYGONS, start=1):\n",
    "        if point_in_polygon((cx, cy), poly):\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "# ================== CAMERA THREAD =================\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    print(f\"[CAM {cam_id}] Stream started\", flush=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "# ================== YOLO THREAD =================\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        human_detected = False\n",
    "        detected_segment = None\n",
    "\n",
    "        results = model.predict(\n",
    "            frame,\n",
    "            conf=CONFIDENCE,\n",
    "            imgsz=IMG_SIZE,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                for box in r.boxes:\n",
    "                    if int(box.cls[0]) == 0:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        cx = (x1 + x2) // 2\n",
    "                        cy = (y1 + y2) // 2\n",
    "\n",
    "                        if cam_id == 2 and point_in_polygon((cx, cy), IGNORE_POLYGON_CAM2):\n",
    "                            continue\n",
    "\n",
    "                        human_detected = True\n",
    "\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(display_frame, \"Human\", (x1, y1 - 5),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "                        if cam_id == 3:\n",
    "                            detected_segment = get_segment_id(cx, cy)\n",
    "                        break\n",
    "\n",
    "        # -------- DISPLAY CAM 2 --------\n",
    "        if cam_id == 2:\n",
    "            for i in range(len(IGNORE_POLYGON_CAM2)):\n",
    "                cv2.line(display_frame,\n",
    "                         IGNORE_POLYGON_CAM2[i],\n",
    "                         IGNORE_POLYGON_CAM2[(i + 1) % len(IGNORE_POLYGON_CAM2)],\n",
    "                         (255, 0, 0), 2)\n",
    "\n",
    "            cv2.putText(display_frame, \"IGNORE ZONE\",\n",
    "                        IGNORE_POLYGON_CAM2[0],\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"CAM 2 - Ignore Zone\", display_frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        # -------- DISPLAY CAM 3 --------\n",
    "        if cam_id == 3:\n",
    "            for idx, poly in enumerate(POLYGONS, start=1):\n",
    "                for i in range(len(poly)):\n",
    "                    cv2.line(display_frame, poly[i], poly[(i + 1) % len(poly)], (0, 255, 255), 2)\n",
    "                cv2.putText(display_frame, f\"SEG {idx}\", poly[0],\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "            if detected_segment is not None:\n",
    "                cv2.putText(display_frame, f\"DETECTED SEG {detected_segment}\",\n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"CAM 3 - Segmented\", display_frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        # -------- STATE HANDLING --------\n",
    "        if human_detected:\n",
    "            last_detect_ts[cam_id] = time.time()\n",
    "            if cam_id == 3 and detected_segment is not None:\n",
    "                publish_state(cam_id, str(detected_segment))\n",
    "            else:\n",
    "                publish_state(cam_id, \"1\")\n",
    "\n",
    "        if last_state[cam_id] and time.time() - last_detect_ts[cam_id] > AUTO_OFF_SECONDS:\n",
    "            publish_state(cam_id, \"0\")\n",
    "\n",
    "# ================== MAIN =================\n",
    "def main():\n",
    "    for i, url in enumerate(CAMERA_URLS, start=1):\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        threading.Thread(target=camera_reader, args=(url, q, i), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker, args=(q, i), daemon=True).start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt\n",
    "import numpy as np\n",
    "\n",
    "# ================= MQTT =================\n",
    "MQTT_BROKER = \"10.1.193.80\"\n",
    "MQTT_PORT = 1883\n",
    "\n",
    "CAMERA_TOPIC = {\n",
    "    1: \"classroom/room1\",\n",
    "    2: \"classroom/room2\",\n",
    "    3: \"classroom/room3\"\n",
    "}\n",
    "\n",
    "# ================= CAMERA =================\n",
    "CAMERA_URLS = {\n",
    "    1: \"rtsp://admin:SRMist@2022@10.1.194.79:554/Streaming/Channels/102\",\n",
    "    2: \"rtsp://admin:SRMist@2022@10.1.194.90:554/Streaming/Channels/102\",\n",
    "    3: \"rtsp://admin:SRMist@2022@10.1.194.93:554/Streaming/Channels/101\"\n",
    "}\n",
    "\n",
    "CONFIDENCE = 0.25\n",
    "IMG_SIZE = 320\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "SKIP_FRAMES = 2\n",
    "OFF_DELAY = 5\n",
    "\n",
    "# ================= STATE =================\n",
    "binary_state = {1: False, 2: False}\n",
    "active_segment = None\n",
    "last_seen = {1: 0, 2: 0, 3: 0}\n",
    "\n",
    "# ================= MQTT =================\n",
    "mqtt_client = mqtt.Client(client_id=f\"YOLO_PC_{int(time.time())}\")\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "# ================= YOLO =================\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ================= POLYGONS (CAM 3) =================\n",
    "POLYGONS = [\n",
    "    [(29,107),(142,72),(232,103),(59,164)],\n",
    "    [(67,169),(104,221),(318,132),(243,103)],\n",
    "    [(330,136),(478,184),(463,267),(57,251)],\n",
    "    [(145,69),(253,40),(338,60),(241,99)],\n",
    "    [(346,67),(423,85),(327,128),(254,102)],\n",
    "    [(335,131),(437,89),(478,106),(479,174)]\n",
    "]\n",
    "\n",
    "def point_in_polygon(pt, poly):\n",
    "    x, y = pt\n",
    "    inside = False\n",
    "    px, py = poly[0]\n",
    "    for i in range(1, len(poly) + 1):\n",
    "        sx, sy = poly[i % len(poly)]\n",
    "        if ((sy > y) != (py > y)) and \\\n",
    "           (x < (px - sx) * (y - sy) / (py - sy + 1e-6) + sx):\n",
    "            inside = not inside\n",
    "        px, py = sx, sy\n",
    "    return inside\n",
    "\n",
    "def get_segment(cx, cy):\n",
    "    for i, poly in enumerate(POLYGONS, start=1):\n",
    "        if point_in_polygon((cx, cy), poly):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "# ================= CAMERA THREAD =================\n",
    "def camera_reader(cam_id, frame_queue):\n",
    "    cap = cv2.VideoCapture(CAMERA_URLS[cam_id], cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(CAMERA_URLS[cam_id], cv2.CAP_FFMPEG)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "# ================= YOLO THREAD =================\n",
    "def yolo_worker(cam_id, frame_queue):\n",
    "    global active_segment\n",
    "    frame_count = 0\n",
    "\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        frame_count += 1\n",
    "\n",
    "        # ===== DRAW SEGMENTATION (CAM 3 ONLY) =====\n",
    "        if cam_id == 3:\n",
    "            for idx, poly in enumerate(POLYGONS, start=1):\n",
    "                pts = np.array(poly, np.int32)\n",
    "                cv2.polylines(frame, [pts], True, (255, 255, 0), 2)\n",
    "\n",
    "                cx = int(np.mean(pts[:, 0]))\n",
    "                cy = int(np.mean(pts[:, 1]))\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"S{idx}\",\n",
    "                    (cx - 10, cy),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "        if frame_count % (SKIP_FRAMES + 1) != 0:\n",
    "            cv2.imshow(window_name, frame)\n",
    "            cv2.waitKey(1)\n",
    "            continue\n",
    "\n",
    "        now = time.time()\n",
    "        human_detected = False\n",
    "        detected_segment = None\n",
    "\n",
    "        results = model.predict(\n",
    "            frame,\n",
    "            conf=CONFIDENCE,\n",
    "            imgsz=IMG_SIZE,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                for box in r.boxes:\n",
    "                    if int(box.cls[0]) == 0:\n",
    "                        human_detected = True\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        cx = (x1 + x2) // 2\n",
    "                        cy = (y1 + y2) // 2\n",
    "\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "                        cv2.putText(frame, \"Person\", (x1, y1 - 5),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "                        if cam_id == 3:\n",
    "                            detected_segment = get_segment(cx, cy)\n",
    "                            if detected_segment:\n",
    "                                cv2.putText(\n",
    "                                    frame,\n",
    "                                    f\"SEG {detected_segment}\",\n",
    "                                    (cx - 20, cy - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    0.6,\n",
    "                                    (0, 0, 255),\n",
    "                                    2\n",
    "                                )\n",
    "                        break\n",
    "\n",
    "        # -------- CAM 1 & 2 --------\n",
    "        if cam_id in [1, 2]:\n",
    "            if human_detected:\n",
    "                last_seen[cam_id] = now\n",
    "                if not binary_state[cam_id]:\n",
    "                    mqtt_client.publish(CAMERA_TOPIC[cam_id], \"1\", retain=False)\n",
    "                    binary_state[cam_id] = True\n",
    "                    print(f\"[CAM {cam_id}] ON\")\n",
    "            else:\n",
    "                if binary_state[cam_id] and now - last_seen[cam_id] > OFF_DELAY:\n",
    "                    mqtt_client.publish(CAMERA_TOPIC[cam_id], \"0\", retain=False)\n",
    "                    binary_state[cam_id] = False\n",
    "                    print(f\"[CAM {cam_id}] OFF\")\n",
    "\n",
    "        # -------- CAM 3 --------\n",
    "        if cam_id == 3:\n",
    "            if human_detected and detected_segment is not None:\n",
    "                last_seen[3] = now\n",
    "\n",
    "                if active_segment != detected_segment:\n",
    "                    if active_segment is not None:\n",
    "                        mqtt_client.publish(\n",
    "                            CAMERA_TOPIC[3],\n",
    "                            f\"S{active_segment}_OFF\",\n",
    "                            retain=False\n",
    "                        )\n",
    "\n",
    "                    mqtt_client.publish(\n",
    "                        CAMERA_TOPIC[3],\n",
    "                        f\"S{detected_segment}_ON\",\n",
    "                        retain=False\n",
    "                    )\n",
    "                    print(f\"[CAM 3] SEG {detected_segment} ON\")\n",
    "                    active_segment = detected_segment\n",
    "\n",
    "            elif active_segment is not None and now - last_seen[3] > OFF_DELAY:\n",
    "                mqtt_client.publish(\n",
    "                    CAMERA_TOPIC[3],\n",
    "                    f\"S{active_segment}_OFF\",\n",
    "                    retain=False\n",
    "                )\n",
    "                print(f\"[CAM 3] SEG {active_segment} OFF\")\n",
    "                active_segment = None\n",
    "\n",
    "        cv2.imshow(window_name, frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "# ================= MAIN =================\n",
    "def main():\n",
    "    for cam_id in CAMERA_URLS:\n",
    "        q = queue.Queue(maxsize=1)\n",
    "        threading.Thread(target=camera_reader,\n",
    "                         args=(cam_id, q), daemon=True).start()\n",
    "        threading.Thread(target=yolo_worker,\n",
    "                         args=(cam_id, q), daemon=True).start()\n",
    "\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82426304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTRUCTIONS:\n",
      "• Press 'm' → switch mode (line/polygon)\n",
      "• Line Mode: Click TWO points → ONE line\n",
      "• Polygon Mode: Click FOUR points → ONE slanted box/polygon\n",
      "• Press 'n' → next segment (lines only)\n",
      "• Press 'q' → quit\n",
      "\n",
      "Current mode: line\n",
      "Clicked: (269, 41)\n",
      "Clicked: (477, 138)\n",
      "Line saved: (269, 41) -> (477, 138)\n",
      "Switched mode: polygon\n",
      "Clicked: (1, 126)\n",
      "Clicked: (266, 40)\n",
      "Clicked: (475, 138)\n",
      "Clicked: (476, 262)\n",
      "Clicked: (4, 134)\n",
      "Polygon saved: [(1, 126), (266, 40), (475, 138), (476, 262), (4, 134)]\n",
      "Clicked: (267, 37)\n",
      "Clicked: (322, 32)\n",
      "Clicked: (472, 70)\n",
      "Clicked: (477, 135)\n",
      "Clicked: (268, 38)\n",
      "Polygon saved: [(267, 37), (322, 32), (472, 70), (477, 135), (268, 38)]\n",
      "\n",
      "================ FINAL OUTPUT ================\n",
      "\n",
      "SEGMENT 1\n",
      "  (269, 41) -> (477, 138)\n",
      "\n",
      "================ POLYGONS ================\n",
      "POLY 1: [(1, 126), (266, 40), (475, 138), (476, 262), (4, 134)]\n",
      "POLY 2: [(267, 37), (322, 32), (472, 70), (477, 135), (268, 38)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# ================== CAMERA ==================\n",
    "RTSP_URL = \"rtsp://admin:SRMist@2022@10.1.194.104:554/Streaming/Channels/101\"\n",
    "\n",
    "cap = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open camera\")\n",
    "    exit(1)\n",
    "\n",
    "# ================== RESIZE CONFIG ==================\n",
    "FRAME_WIDTH = 480\n",
    "FRAME_HEIGHT = 270\n",
    "\n",
    "# ================== STATE ==================\n",
    "current_points = []\n",
    "segments = {}  # for lines\n",
    "polygons = {}  # for slanted boxes/polygons\n",
    "seg_id = 1\n",
    "poly_id = 1\n",
    "frame_for_draw = None\n",
    "mode = \"line\"  # modes: \"line\" or \"polygon\"\n",
    "\n",
    "# ================== MOUSE CALLBACK ==================\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global frame_for_draw, seg_id, poly_id\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        current_points.append((x, y))\n",
    "        print(f\"Clicked: ({x}, {y})\")\n",
    "        frame_for_draw = frame.copy()\n",
    "\n",
    "        if mode == \"line\":\n",
    "            # Draw existing lines\n",
    "            for line in segments.get(seg_id, []):\n",
    "                cv2.line(frame_for_draw, line[0], line[1], (0, 255, 0), 2)\n",
    "\n",
    "            # Draw current line preview\n",
    "            if len(current_points) == 1:\n",
    "                cv2.circle(frame_for_draw, current_points[0], 5, (0, 0, 255), -1)\n",
    "            elif len(current_points) == 2:\n",
    "                p1, p2 = current_points\n",
    "                cv2.line(frame_for_draw, p1, p2, (255, 0, 0), 2)\n",
    "                cv2.circle(frame_for_draw, p1, 5, (0, 0, 255), -1)\n",
    "                cv2.circle(frame_for_draw, p2, 5, (0, 0, 255), -1)\n",
    "                segments.setdefault(seg_id, []).append((p1, p2))\n",
    "                print(f\"Line saved: {p1} -> {p2}\")\n",
    "                current_points.clear()\n",
    "\n",
    "        elif mode == \"polygon\":\n",
    "            # Draw existing polygons\n",
    "            for pid, pts in polygons.items():\n",
    "                for i in range(len(pts)):\n",
    "                    cv2.line(frame_for_draw, pts[i], pts[(i + 1) % len(pts)], (255, 255, 0), 2)\n",
    "                cv2.putText(frame_for_draw, f\"POLY {pid}\", pts[0], cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw current polygon preview\n",
    "            for i in range(len(current_points) - 1):\n",
    "                cv2.line(frame_for_draw, current_points[i], current_points[i + 1], (255, 0, 255), 2)\n",
    "            if len(current_points) == 5:\n",
    "                # close polygon\n",
    "                cv2.line(frame_for_draw, current_points[3], current_points[0], (255, 0, 255), 2)\n",
    "                polygons[poly_id] = current_points.copy()\n",
    "                print(f\"Polygon saved: {current_points}\")\n",
    "                poly_id += 1\n",
    "                current_points.clear()\n",
    "\n",
    "# ================== WINDOW ==================\n",
    "cv2.namedWindow(\"LIVE CAM - DRAW LINES/POLYGONS\")\n",
    "cv2.setMouseCallback(\"LIVE CAM - DRAW LINES/POLYGONS\", mouse_click)\n",
    "\n",
    "print(\"\\nINSTRUCTIONS:\")\n",
    "print(\"• Press 'm' → switch mode (line/polygon)\")\n",
    "print(\"• Line Mode: Click TWO points → ONE line\")\n",
    "print(\"• Polygon Mode: Click FOUR points → ONE slanted box/polygon\")\n",
    "print(\"• Press 'n' → next segment (lines only)\")\n",
    "print(\"• Press 'q' → quit\\n\")\n",
    "print(f\"Current mode: {mode}\")\n",
    "\n",
    "# ================== MAIN LOOP ==================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "    display = frame.copy()\n",
    "\n",
    "    # Draw saved lines\n",
    "    for lines in segments.get(seg_id, []):\n",
    "        cv2.line(display, lines[0], lines[1], (0, 255, 0), 2)\n",
    "\n",
    "    # Draw saved polygons\n",
    "    for pid, pts in polygons.items():\n",
    "        for i in range(len(pts)):\n",
    "            cv2.line(display, pts[i], pts[(i + 1) % len(pts)], (255, 255, 0), 2)\n",
    "        cv2.putText(display, f\"POLY {pid}\", pts[0], cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    # Draw current line preview\n",
    "    if mode == \"line\" and len(current_points) == 1:\n",
    "        cv2.circle(display, current_points[0], 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Draw current polygon preview\n",
    "    if mode == \"polygon\" and 1 <= len(current_points) < 6:\n",
    "        for i in range(len(current_points) - 1):\n",
    "            cv2.line(display, current_points[i], current_points[i + 1], (255, 0, 255), 2)\n",
    "        for p in current_points:\n",
    "            cv2.circle(display, p, 3, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"LIVE CAM - DRAW LINES/POLYGONS\", display)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('m'):\n",
    "        mode = \"polygon\" if mode == \"line\" else \"line\"\n",
    "        print(f\"Switched mode: {mode}\")\n",
    "        current_points.clear()\n",
    "\n",
    "    elif key == ord('n') and mode == \"line\":\n",
    "        print(f\"\\nSegment {seg_id} saved with {len(segments.get(seg_id, []))} lines\")\n",
    "        seg_id += 1\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ================== FINAL OUTPUT ==================\n",
    "print(\"\\n================ FINAL OUTPUT ================\")\n",
    "for sid, lines in segments.items():\n",
    "    print(f\"\\nSEGMENT {sid}\")\n",
    "    for l in lines:\n",
    "        print(f\"  {l[0]} -> {l[1]}\")\n",
    "\n",
    "print(\"\\n================ POLYGONS ================\")\n",
    "for pid, pts in polygons.items():\n",
    "    print(f\"POLY {pid}: {pts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
