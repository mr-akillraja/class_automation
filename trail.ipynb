{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5934563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "\n",
    "# -----------------------\n",
    "# 2 CAMERA STREAM URLS\n",
    "\n",
    "# -----------------------\n",
    "CAMERA_URLS = [\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.107:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.84:554/Streaming/Channels/101\",\n",
    "    \"rtsp://admin:SRMist@2022@10.1.194.88:554/Streaming/Channels/101\",\n",
    "       \"rtsp://admin:SRMist@2022@10.1.194.99:554/Streaming/Channels/101\",   # cam_id = \n",
    "\n",
    "]\n",
    "\n",
    "CONFIDENCE = 0.3\n",
    "FRAME_WIDTH = 630\n",
    "\n",
    "\n",
    "FRAME_HEIGHT = 480\n",
    "SKIP_FRAMES = 2   \n",
    "# YOLO every 3rd frame → reduces load\n",
    "\n",
    "# Raspberry Pi HTTP server\n",
    "PI_IP = \"10.1.193.78\"\n",
    "PI_PORT = 5000\n",
    "\n",
    "\n",
    "AUTO_OFF_SECONDS = 6\n",
    "MIN_HTTP_INTERVAL = 0.5  # seconds between HTTP calls per camera\n",
    "\n",
    "# Load model\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# HTTP helper (non-blocking)\n",
    "def send_relay_command(cam_id, state):\n",
    "    url = f\"http://{PI_IP}:{PI_PORT}/room{cam_id}/{state}\"\n",
    "    def _do_request(u):\n",
    "        try:\n",
    "            r = requests.get(u, timeout=1.0)\n",
    "        except Exception as e:\n",
    "            print(f\"[NET] Failed to send {u}: {e}\")    \n",
    "    t = threading.Thread(target=_do_request, args=(url,), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "last_http_ts = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "last_state = {i+1: False for i in range(len(CAMERA_URLS))}\n",
    "last_detection_time = {i+1: 0 for i in range(len(CAMERA_URLS))}\n",
    "\n",
    "def publish_state_if_changed(cam_id, new_state):\n",
    "    now = time.time()\n",
    "    if new_state:\n",
    "        last_detection_time[cam_id] = now\n",
    "\n",
    "    if new_state != last_state[cam_id]:\n",
    "\n",
    "        if now - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "            state_str = \"on\" if new_state else \"off\"\n",
    "            send_relay_command(cam_id, state_str)\n",
    "            last_http_ts[cam_id] = now\n",
    "            last_state[cam_id] = new_state\n",
    "            print(f\"[HTTP] room{cam_id} -> {state_str.upper()}\")\n",
    "\n",
    "def camera_reader(url, frame_queue, cam_id):\n",
    "    cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[CAM {cam_id}] ERROR: Cannot open RTSP stream\")\n",
    "        return\n",
    "    print(f\"[CAM {cam_id}] Stream OK\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[CAM {cam_id}] Reconnecting...\")\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            continue\n",
    "        resized = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        if frame_queue.full():\n",
    "            try: frame_queue.get_nowait()\n",
    "            except: pass\n",
    "        frame_queue.put(resized)\n",
    "\n",
    "def yolo_worker(frame_queue, cam_id):\n",
    "    window_name = f\"CAM {cam_id}\"\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_counter += 1\n",
    "            if frame_counter % (SKIP_FRAMES + 1) == 0:\n",
    "                results = model(frame, conf=CONFIDENCE, verbose=False)\n",
    "                human_detected = False\n",
    "                for r in results:\n",
    "                    if r.boxes is None:\n",
    "                        continue\n",
    "                    for cls in r.boxes.cls.cpu().numpy():\n",
    "                        if int(cls) == 0:\n",
    "                            human_detected = True\n",
    "                            break\n",
    "                    if human_detected:\n",
    "                        break\n",
    "                if human_detected:\n",
    "                    print(f\"[CAM {cam_id}] HUMAN\")\n",
    "                else:\n",
    "                    print(f\"[CAM {cam_id}] NO HUMAN\")\n",
    "                publish_state_if_changed(cam_id, human_detected)\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Auto-off if no detection for AUTO_OFF_SECONDS\n",
    "        if last_state[cam_id] and (time.time() - last_detection_time[cam_id]) > AUTO_OFF_SECONDS:\n",
    "            if time.time() - last_http_ts[cam_id] >= MIN_HTTP_INTERVAL:\n",
    "                send_relay_command(cam_id, \"off\")\n",
    "                last_http_ts[cam_id] = time.time()\n",
    "                last_state[cam_id] = False\n",
    "                print(f\"[AUTO-OFF] room{cam_id} -> OFF (no detection for {AUTO_OFF_SECONDS}s)\")\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start threads\n",
    "frame_queues = []\n",
    "num_cams = len(CAMERA_URLS)\n",
    "for i, url in enumerate(CAMERA_URLS):\n",
    "    cam_id = i + 1\n",
    "    q = queue.Queue(maxsize=1)\n",
    "    frame_queues.append(q)\n",
    "    threading.Thread(target=camera_reader, args=(url, q, cam_id), daemon=True).start()\n",
    "    threading.Thread(target=yolo_worker, args=(q, cam_id), daemon=True).start()\n",
    "\n",
    "print(f\"{num_cams}-Camera Human Detection Running...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ===================== FILE PATH =====================\n",
    "LOG_FILE = r\"C:\\Users\\Admin\\PyCharmMiscProject\\final_code\\logs\\camera_detection.log\"\n",
    "\n",
    "# ===================== REGEX =====================\n",
    "CPU_PATTERN = re.compile(\n",
    "    r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d+)\\s+\\|\\s+'\n",
    "    r'INFO\\s+\\|\\s+CPU\\s+\\|\\s+'\n",
    "    r'system=\\s*(?P<system>[\\d.]+)%\\s+\\|\\s+'\n",
    "    r'process=\\s*(?P<process>[\\d.]+)%'\n",
    ")\n",
    "\n",
    "DETECT_PATTERN = re.compile(\n",
    "    r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d+).*HUMAN_DETECTED'\n",
    ")\n",
    "\n",
    "# ===================== STORAGE =====================\n",
    "cpu_rows = []\n",
    "detect_rows = []\n",
    "\n",
    "# ===================== READ LOG =====================\n",
    "with open(LOG_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        cpu_match = CPU_PATTERN.search(line)\n",
    "        if cpu_match:\n",
    "            cpu_rows.append({\n",
    "                \"timestamp\": cpu_match.group(\"timestamp\"),\n",
    "                \"system_cpu\": float(cpu_match.group(\"system\")),\n",
    "                \"process_cpu\": float(cpu_match.group(\"process\"))\n",
    "            })\n",
    "\n",
    "        detect_match = DETECT_PATTERN.search(line)\n",
    "        if detect_match:\n",
    "            detect_rows.append({\n",
    "                \"timestamp\": detect_match.group(\"timestamp\")\n",
    "            })\n",
    "\n",
    "# ===================== CREATE DATAFRAMES =====================\n",
    "\n",
    "cpu_df = pd.DataFrame(cpu_rows)\n",
    "detect_df = pd.DataFrame(detect_rows)\n",
    "\n",
    "cpu_df[\"timestamp\"] = pd.to_datetime(cpu_df[\"timestamp\"])\n",
    "detect_df[\"timestamp\"] = pd.to_datetime(detect_df[\"timestamp\"])\n",
    "\n",
    "cpu_df = cpu_df.sort_values(\"timestamp\")\n",
    "detect_df = detect_df.sort_values(\"timestamp\")\n",
    "\n",
    "# ===================== AGGREGATION (1 MIN) =====================\n",
    "cpu_1min = (\n",
    "    cpu_df\n",
    "    .set_index(\"timestamp\")\n",
    "    .resample(\"1T\")\n",
    "    .agg(\n",
    "        avg_cpu=(\"system_cpu\", \"mean\"),\n",
    "        max_cpu=(\"system_cpu\", \"max\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "detect_1min = (\n",
    "    detect_df\n",
    "    .set_index(\"timestamp\")\n",
    "    .resample(\"1T\")\n",
    "    .size()\n",
    "    .reset_index(name=\"detections\")\n",
    ")\n",
    "\n",
    "# ===================== MERGE =====================\n",
    "plot_df = pd.merge(cpu_1min, detect_1min, on=\"timestamp\", how=\"left\")\n",
    "plot_df[\"detections\"] = plot_df[\"detections\"].fillna(0)\n",
    "\n",
    "# ===================== PLOT =====================\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# CPU Lines\n",
    "ax1.plot(\n",
    "    plot_df[\"timestamp\"],\n",
    "    plot_df[\"avg_cpu\"],\n",
    "    linewidth=2,\n",
    "    label=\"Average CPU (%)\"\n",
    ")\n",
    "ax1.plot(\n",
    "    plot_df[\"timestamp\"],\n",
    "    plot_df[\"max_cpu\"],\n",
    "    linestyle=\"--\",\n",
    "    label=\"Max CPU (%)\"\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Time\")\n",
    "ax1.set_ylabel(\"CPU Usage (%)\")\n",
    "ax1.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# Detection Bars\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(\n",
    "    plot_df[\"timestamp\"],\n",
    "    plot_df[\"detections\"],\n",
    "    width=0.0008,\n",
    "    alpha=0.3,\n",
    "    label=\"Detections / min\"\n",
    ")\n",
    "ax2.set_ylabel(\"Detection Count\")\n",
    "\n",
    "# ===================== FORMATTING =====================\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "\n",
    "fig.suptitle(\n",
    "    \"System CPU Usage vs Human Detection Density (1-Minute Aggregation)\",\n",
    "    fontsize=14,\n",
    "    weight=\"bold\"\n",
    ")\n",
    "\n",
    "fig.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"✅ GPU is available and TensorFlow can see it\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"GPU {i}: {gpu.name}\")\n",
    "else:\n",
    "    print(\"❌ GPU is NOT available. TensorFlow is running on CPU\")\n",
    "\n",
    "# Optional: confirm TensorFlow build\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Optional: simple GPU operation test\n",
    "with tf.device('/GPU:0' if gpus else '/CPU:0'):\n",
    "    a = tf.random.normal([1000, 1000])\n",
    "    b = tf.matmul(a, a)\n",
    "    print(\"Matrix multiplication device:\", b.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ada5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
